# configs/config_debug.yaml
# Inherit from the main config and override specific values for debugging
defaults:
  - config # Loads config.yaml first

# Override Model & Tokenizer for the tiny debug model
model:
  name: "sbintuitions/tiny-lm-chat" # Use the specified tiny model
  tokenizer_name: "sbintuitions/tiny-lm-chat"
  trust_remote_code: false # Likely not needed for this model based on HF card
  torch_dtype: "float32"
# Adjust PPO params for faster testing on CPU
ppo:
  learning_rate: 5.0e-5 # Can use higher LR for smaller models usually
  batch_size: 2       # Smaller batch size for CPU memory
  mini_batch_size: 1
  gradient_accumulation_steps: 1
  use_8bit_adam: true
  rollout_samples: 4

# Adjust Training Control for fast debugging runs
training:
  total_ppo_steps: 2  # Run only a couple of steps
  log_interval: 1
  save_interval: 2
  output_dir: "outputs/ppo_gsm8k_debug_tiny"
  device: "cpu"       # Force CPU execution
  num_samples: 8

# Optional: Adjust generation parameters if needed (defaults might be fine)
# generation:
#   temperature: 0.8

wandb:
  report_to_wandb: false
